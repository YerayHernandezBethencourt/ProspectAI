{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yera_\\Documents\\Areas\\En proceso\\Qualentum-Proyectos\\ProspectAI\\ProspectAI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Cargar las librerías necesarias\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Determinar el dispositivo a usar (CPU o GPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../prospectos/train/alprazolan/alprazolan.JPG\"\n",
    "# Abre la imagen directamente desde la ruta\n",
    "image = Image.open(img_path)\n",
    "prompt = 'Examina el prospecto médico de la imagen y enumera los detalles más importantes relacionados con: - Qué es el medicamento. - Para qué se utiliza el medicamento. - Precauciones antes de tomarlo. - Forma de tomarlo. - Efectos adversos del fármaco. - Conservación del fármaco. - Información adicional.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00,  9.44it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModel.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5', trust_remote_code=True, torch_dtype=torch.float16)\n",
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniCPMV(\n",
       "  (llm): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "  )\n",
       "  (vpm): Idefics2VisionTransformer(\n",
       "    (embeddings): Idefics2VisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "      (position_embedding): Embedding(4900, 1152)\n",
       "    )\n",
       "    (encoder): Idefics2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-26): 27 x Idefics2EncoderLayer(\n",
       "          (self_attn): Idefics2VisionAttention(\n",
       "            (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Idefics2VisionMLP(\n",
       "            (activation_fn): PytorchGELUTanh()\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (resampler): Resampler(\n",
       "    (kv_proj): Linear(in_features=1152, out_features=4096, bias=False)\n",
       "    (attn): MultiheadAttention(\n",
       "      (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    )\n",
       "    (ln_q): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
       "    (ln_kv): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
       "    (ln_post): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5', trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../prospectos/train/alprazolan/alprazolan.JPG\"\n",
    "# Abre la imagen directamente desde la ruta\n",
    "image = Image.open(img_path)\n",
    "question = 'Examina el prospecto médico de la imagen y enumera los detalles más importantes relacionados con: - Qué es el medicamento. - Para qué se utiliza el medicamento. - Precauciones antes de tomarlo. - Forma de tomarlo. - Efectos adversos del fármaco. - Conservación del fármaco. - Información adicional.'\n",
    "msgs = [{'role': 'user', 'content': question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yera_\\Documents\\Areas\\En proceso\\Qualentum-Proyectos\\ProspectAI\\ProspectAI\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yera_\\.cache\\huggingface\\hub\\models--openbmb--MiniCPM-Llama3-V-2_5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "A new version of the following files was downloaded from https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5:\n",
      "- image_processing_minicpmv.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5:\n",
      "- processing_minicpmv.py\n",
      "- image_processing_minicpmv.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "c:\\Users\\yera_\\Documents\\Areas\\En proceso\\Qualentum-Proyectos\\ProspectAI\\ProspectAI\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\image_processing_auto.py:513: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\yera_\\Documents\\Areas\\En proceso\\Qualentum-Proyectos\\ProspectAI\\ProspectAI\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:603: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El prospecto médico en la imagen proporciona una variedad de detalles importantes sobre el medicamento. Aunque los textos están desenfocados, podemos identificar algunos puntos clave:\n",
      "\n",
      "- El medicamento se refiere a un \"Alprazolam 0,25 mg compuesto por...\". Esto sugiere que el medicamento es un compuesto de alprazolam en una dosis de 0,25 mg.\n",
      "\n",
      "- La indicación del medicamento se menciona como \"para el tratamiento de ansiedad y síndrome de estrés post-traumático (SST)\". Esto indica que el medicamento está destinado para ayudar con la ansiedad y el SST.\n",
      "\n",
      "- Las precauciones antes de tomar el medicamento incluyen \"no tomar si está alérgico a alprazolam o si tiene hipersensibilidad conocida a benzodiazepinas\". Esto alerta a los pacientes potenciales sobre posibles reacciones adversas o contraindicaciones.\n",
      "\n",
      "- La forma de administración no está claramente visible, pero generalmente, los benzodiazepínicos como el alprazolam se toman oralmente.\n",
      "\n",
      "- Los efectos adversos del medicamento se mencionan brevemente, aunque los detalles específicos no son discernibles debido al desenfoque.\n",
      "\n",
      "- La conservación del medicamento se menciona, pero los detalles exactos no son visibles.\n",
      "\n",
      "- Información adicional se proporciona, pero los detalles específicos no pueden ser determinados debido al desenfoque.\n",
      "\n",
      "Para obtener información detallada y precisa sobre el medicamento, se recomienda leer el prospecto médico completo o consultar a un profesional de la salud.\n"
     ]
    }
   ],
   "source": [
    "res = model.chat(\n",
    "    image=image,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer,\n",
    "    sampling=True, # if sampling=False, beam_search will be used by default\n",
    "    temperature=0.1,\n",
    "    # system_prompt='' # pass system_prompt if needed\n",
    ")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
